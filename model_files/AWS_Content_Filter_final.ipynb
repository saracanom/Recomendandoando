{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python3\",\n",
    "          \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "          \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "          \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1747168862658_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-42-57.us-east-2.compute.internal:20888/proxy/application_1747168862658_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-41-150.us-east-2.compute.internal:8042/node/containerlogs/container_1747168862658_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.13.0)\n",
      "Installing collected packages: tzdata, python-dateutil, numpy, pandas\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Not uninstalling python-dateutil at /usr/lib/python3.9/site-packages, outside environment /mnt1/yarn/usercache/livy/appcache/application_1747168862658_0001/container_1747168862658_0001_01_000001/tmp/spark-5846d2fa-57cb-4dd9-88b3-1a8b139f971a\n",
      "    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 python-dateutil-2.9.0.post0 tzdata-2025.2\n",
      "\n",
      "Requirement already satisfied: numpy in ./tmp/spark-5846d2fa-57cb-4dd9-88b3-1a8b139f971a/lib64/python3.9/site-packages (2.0.2)\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 2.23.11 requires python-dateutil<=2.9.0,>=2.1, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag."
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iVTrnoKgkCG_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, collect_list\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import lower, regexp_replace, split\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import trim, col\n",
    "from pyspark.sql.functions import filter as array_filter\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col, udf, desc\n",
    "from pyspark.sql.types import DoubleType\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Movies\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BaRNlzt_kKx5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies_filtered loaded in 8.98 s"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "movies_cleaned = (\n",
    "    spark.read\n",
    "         .option(\"header\",    \"true\")\n",
    "         .option(\"inferSchema\",\"true\")\n",
    "         .csv(\"s3://recomendandoando/processed/movies_filtered/\")\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\" Movies_filtered loaded in {end - start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXzh3J0_kMfq",
    "outputId": "1bbc63df-176a-4da5-ac1b-5b3fdfd1f3a3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|filter_text_clean                                            |\n",
      "+-------------------------------------------------------------+\n",
      "|[toy, story, adventure, animation, children, comedy, fantasy]|\n",
      "|[jumanji, adventure, children, fantasy]                      |\n",
      "|[grumpier, old, men, comedy, romance]                        |\n",
      "|[waiting, exhale, comedy, drama, romance]                    |\n",
      "|[father, bride, part, ii, comedy]                            |\n",
      "|[heat, action, crime, thriller]                              |\n",
      "|[sabrina, comedy, romance]                                   |\n",
      "|[tom, huck, adventure, children]                             |\n",
      "|[sudden, death, action]                                      |\n",
      "|[goldeneye, action, adventure, thriller]                     |\n",
      "|[american, president, comedy, drama, romance]                |\n",
      "|[dracula, dead, loving, comedy, horror]                      |\n",
      "|[balto, adventure, animation, children]                      |\n",
      "|[nixon, drama]                                               |\n",
      "|[cutthroat, island, action, adventure, romance]              |\n",
      "|[casino, crime, drama]                                       |\n",
      "|[sense, sensibility, drama, romance]                         |\n",
      "|[four, rooms, comedy]                                        |\n",
      "|[ace, ventura, nature, calls, comedy]                        |\n",
      "|[money, train, action, comedy, crime, drama, thriller]       |\n",
      "+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Clean time: 1.14 s"
     ]
    }
   ],
   "source": [
    "# Transformar el texto para vectorizarlo\n",
    "start = time.perf_counter()\n",
    "movies_cleaned = movies_cleaned.withColumn(\"combined_text\", concat_ws(\" \",\"title\", \"genres\"))\n",
    "# Texto en minusculas y eliminar caracteres especiales\n",
    "movies_cleaned = movies_cleaned.withColumn(\"processed_text\", lower(col(\"combined_text\")))\n",
    "movies_cleaned = movies_cleaned.withColumn(\"processed_text\", regexp_replace(col(\"processed_text\"), \"[^a-zA-Z\\\\s]\", \" \"))\n",
    "\n",
    "# Convertir la columna 'processed_text' en un array de palabras\n",
    "movies_cleaned = movies_cleaned.withColumn(\"words\", split(col(\"processed_text\"), \" \"))\n",
    "\n",
    "# Eliminar stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_text\")\n",
    "movies_cleaned = remover.transform(movies_cleaned)\n",
    "movies_cleaned = movies_cleaned.withColumn(\n",
    "    \"filter_text_clean\",\n",
    "    array_filter(col(\"filtered_text\"), lambda x: trim(x) != \"\")\n",
    ")\n",
    "\n",
    "\n",
    "movies_cleaned.select(\"filter_text_clean\").show(truncate=False)\n",
    "end = time.perf_counter()\n",
    "print(f\"Clean time: {end - start:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce6S3JnUkQVP",
    "outputId": "55d9c2b8-08e8-4923-a55d-ef66507e6fd8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing and TD-IDF execution time: 3.92 s\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|movieId|features                                                                                                                                                        |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1      |(20,[1,12,13,15,17,19],[1.467113497528166,0.00954862220713434,2.5735505396155305,2.0569516086221125,2.0988171224776484,1.5756070940813949])                     |\n",
      "|2      |(20,[1,12,13,16,19],[1.467113497528166,0.008355044431242548,1.2867752698077652,2.225940585204374,1.5756070940813949])                                           |\n",
      "|3      |(20,[3,5,6,7,12],[2.1383185373871587,1.8024025903290017,0.9468912533247323,2.3463697406556587,0.00954862220713434])                                             |\n",
      "|4      |(20,[4,6,11,12],[1.4816920190018683,0.9468912533247323,1.5049265270425602,0.00954862220713434])                                                                 |\n",
      "|5      |(20,[0,3,9,12],[3.273641912767828,2.1383185373871587,2.0138426206435174,0.00954862220713434])                                                                   |\n",
      "|6      |(20,[6,7,11,12,13],[0.9468912533247323,2.3463697406556587,1.5049265270425602,0.008355044431242548,1.2867752698077652])                                          |\n",
      "|7      |(20,[6,12],[0.9468912533247323,0.010742199983026134])                                                                                                           |\n",
      "|8      |(20,[1,4,12,13,15],[1.467113497528166,0.7408460095009342,0.008355044431242548,1.2867752698077652,2.0569516086221125])                                           |\n",
      "|9      |(20,[2,8,12,13],[2.3041347245493045,2.038198003859948,0.008355044431242548,1.2867752698077652])                                                                 |\n",
      "|10     |(20,[6,12,13],[0.9468912533247323,0.008355044431242548,3.860325809423296])                                                                                      |\n",
      "|11     |(20,[4,6,12],[0.7408460095009342,1.8937825066494647,0.011935777758917927])                                                                                      |\n",
      "|12     |(20,[6,12,15,16,18],[0.9468912533247323,0.010742199983026134,2.0569516086221125,2.225940585204374,2.306319763656827])                                           |\n",
      "|13     |(20,[1,10,12,13],[1.467113497528166,2.107650106049195,0.008355044431242548,2.5735505396155305])                                                                 |\n",
      "|14     |(20,[0,4,12],[1.636820956383914,0.7408460095009342,0.008355044431242548])                                                                                       |\n",
      "|15     |(20,[6,8,12,13,15],[0.9468912533247323,2.038198003859948,0.008355044431242548,2.5735505396155305,2.0569516086221125])                                           |\n",
      "|16     |(20,[4,11,12],[0.7408460095009342,1.5049265270425602,0.00954862220713434])                                                                                      |\n",
      "|17     |(20,[4,6,7,12],[0.7408460095009342,1.8937825066494647,2.3463697406556587,0.008355044431242548])                                                                 |\n",
      "|18     |(20,[3,4,12],[2.1383185373871587,0.7408460095009342,0.00954862220713434])                                                                                       |\n",
      "|19     |(20,[11,12,14,18],[1.5049265270425602,0.010742199983026134,4.628590603023655,2.306319763656827])                                                                |\n",
      "|20     |(20,[3,4,6,11,12,13,17],[2.1383185373871587,0.7408460095009342,0.9468912533247323,1.5049265270425602,0.00954862220713434,1.2867752698077652,2.0988171224776484])|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# Crear un HashingTF para vectorizar el texto procesado\n",
    "start = time.perf_counter()\n",
    "hashingTF = HashingTF(inputCol=\"filtered_text\", outputCol=\"raw_features\", numFeatures=20)\n",
    "\n",
    "# Calcular TF-IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Pipeline para las transformaciones\n",
    "pipeline = Pipeline(stages=[hashingTF, idf])\n",
    "\n",
    "model = pipeline.fit(movies_cleaned)\n",
    "movies_cleaned = model.transform(movies_cleaned)\n",
    "end = time.perf_counter()\n",
    "print(f\"Hashing and TD-IDF execution time: {end - start:.2f} s\")\n",
    "\n",
    "\n",
    "movies_cleaned.select(\"movieId\", \"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wuXBR3UlQoS",
    "outputId": "b8d78a4f-cace-41c2-d0cb-1dfbd16e52e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix execution time: 0.15 s\n",
      "+-------+-------+---------------------+\n",
      "|movieId|movieId|cosine_sim           |\n",
      "+-------+-------+---------------------+\n",
      "|1      |2      |0.531283421719517    |\n",
      "|1      |3      |5.420238182686733E-6 |\n",
      "|1      |4      |8.83201872225992E-6  |\n",
      "|1      |5      |4.647668127934219E-6 |\n",
      "|1      |6      |0.2310918019925448   |\n",
      "|1      |7      |2.4285195286823596E-5|\n",
      "|1      |8      |0.7417179243571477   |\n",
      "|1      |9      |0.22266185057699128  |\n",
      "|1      |10     |0.560381729705262    |\n",
      "|1      |11     |1.2565158983679533E-5|\n",
      "|1      |12     |0.24171866428401453  |\n",
      "|1      |13     |0.5411721076019801   |\n",
      "|1      |14     |9.955230591563787E-6 |\n",
      "|1      |15     |0.6101948157733894   |\n",
      "|1      |16     |1.2186375080422272E-5|\n",
      "|1      |17     |5.76061651572219E-6  |\n",
      "|1      |18     |9.032851969707335E-6 |\n",
      "|1      |19     |4.269840453332562E-6 |\n",
      "|1      |20     |0.4568134142566331   |\n",
      "|1      |21     |6.494547704413935E-6 |\n",
      "+-------+-------+---------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# Función UDF para calcular la similitud de coseno\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Convertir vectores de SparseVector a arrays\n",
    "    vec1_array = np.array(vec1.toArray())\n",
    "    vec2_array = np.array(vec2.toArray())\n",
    "\n",
    "    # Calcular el producto punto y las longitudes de los vectores\n",
    "    dot_product = np.dot(vec1_array, vec2_array)\n",
    "    norm_a = np.linalg.norm(vec1_array)\n",
    "    norm_b = np.linalg.norm(vec2_array)\n",
    "\n",
    "    # Calcular la similitud de coseno\n",
    "    return float(dot_product / (norm_a * norm_b)) if norm_a and norm_b else 0.0\n",
    "\n",
    "# Registrar la UDF de similitud de coseno\n",
    "cosine_udf = udf(cosine_similarity, DoubleType())\n",
    "start = time.perf_counter()\n",
    "\n",
    "# matriz de similitudes\n",
    "cosine_sim_matrix = movies_cleaned.alias(\"df1\").join(movies_cleaned.alias(\"df2\"), col(\"df1.movieId\") != col(\"df2.movieId\")) \\\n",
    "    .withColumn(\"cosine_sim\", cosine_udf(col(\"df1.features\"), col(\"df2.features\")))\n",
    "end = time.perf_counter()\n",
    "print(f\"Similarity matrix execution time: {end - start:.2f} s\")\n",
    "\n",
    "\n",
    "cosine_sim_matrix.select(\"df1.movieId\", \"df2.movieId\", \"cosine_sim\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "k9UuNgR-lrw1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función para obtener recomendaciones basadas en la similitud de coseno\n",
    "def get_recommendations(movie_name, cosine_sim_matrix, df, top_n=10):\n",
    "    # Buscar el movie_id basado en el nombre\n",
    "    movie_id_row = df.filter(col(\"title\") == movie_name).select(\"movieId\").first()\n",
    "\n",
    "    if movie_id_row is None:\n",
    "        return \"Movie not found\"\n",
    "\n",
    "    movie_id = movie_id_row[\"movieId\"]\n",
    "\n",
    "    # Filtrar las similitudes para el movie_id dado\n",
    "    recommendations = cosine_sim_matrix.filter(col(\"df1.movieId\") == movie_id) \\\n",
    "        .orderBy(desc(\"cosine_sim\")) \\\n",
    "        .select(\"df2.movieId\", \"df2.title\", \"cosine_sim\")\n",
    "\n",
    "    # Mostrar las top_n recomendaciones\n",
    "    recommendations = recommendations.limit(top_n)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcIca6U0qGpc",
    "outputId": "34645604-69fd-4a99-b9bf-b925e4d198bf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------------+------------------+\n",
      "|movieId|title                                                  |cosine_sim        |\n",
      "+-------+-------------------------------------------------------+------------------+\n",
      "|3114   |Toy Story 2 (1999)                                     |0.9999998567812832|\n",
      "|235225 |Once Upon a Snowman (2020)                             |0.9622904605790515|\n",
      "|164576 |Time Raiders (2016)                                    |0.9443553405647069|\n",
      "|249028 |One Piece: Curse of the Sacred Sword (2004)            |0.9428090874299441|\n",
      "|2987   |Who Framed Roger Rabbit? (1988)                        |0.9356978045402591|\n",
      "|255927 |Goat Story With Cheese (2012)                          |0.9355285118023223|\n",
      "|2355   |Bug's Life, A (1998)                                   |0.9355284735301628|\n",
      "|201588 |Toy Story 4 (2019)                                     |0.9355283587139129|\n",
      "|145082 |The Snow Queen 2: Refreeze (2014)                      |0.9271605320461643|\n",
      "|241870 |Mandie and the Secret Tunnel (2009)                    |0.9211233430524529|\n",
      "|159690 |Teenage Mutant Ninja Turtles: Out of the Shadows (2016)|0.9095360075964714|\n",
      "|156427 |Sea Raiders (1941)                                     |0.9051882005337574|\n",
      "|267940 |Silvery Moon (1933)                                    |0.905188158342067 |\n",
      "|193255 |Once Upon a Time, Cinema (1992)                        |0.905188015203599 |\n",
      "|78499  |Toy Story 3 (2010)                                     |0.9041394166598588|\n",
      "|162470 |Cardcaptor Sakura: The Movie (1999)                    |0.9034454774560555|\n",
      "|276251 |DC League of Super-Pets (2022)                         |0.8991374321622714|\n",
      "|110153 |Challenge for Robin Hood, A (1967)                     |0.8961351973982592|\n",
      "|182133 |Mickey and the Seal (1948)                             |0.8961351973982592|\n",
      "|239474 |Lamp Life (2020)                                       |0.8961351973982592|\n",
      "+-------+-------------------------------------------------------+------------------+"
     ]
    }
   ],
   "source": [
    "recommended_movies = get_recommendations(movie_name=\"Toy Story (1995)\", cosine_sim_matrix=cosine_sim_matrix, df=movies_cleaned, top_n=20)\n",
    "recommended_movies.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved to s3://recomendandoando/models/tfidf_content_pipeline"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# `model` is the fitted Pipeline from your code above\n",
    "pipeline_path = \"s3://recomendandoando/models/tfidf_content_pipeline\"\n",
    "recommended_movies.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"s3://recomendandoando/recommendations/content_based/parquet/\")\n",
    "model.write().overwrite().save(pipeline_path)\n",
    "print(f\"Pipeline saved to {pipeline_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For later implementation with new movies\n",
    "## load recs\n",
    "#recs = spark.read.parquet(\"s3://recomendandoando/recommendations/content_based/parquet/\")\n",
    "#recs.show()\n",
    "\n",
    "## load pipeline and re-generate features if you ingest new movies\n",
    "#pipeline = PipelineModel.load(\"s3://recomendandoando/models/tfidf_content_pipeline\")\n",
    "#new_movies = spark.read.csv(\"s3://...\")                # however you ingest more titles\n",
    "#new_featurized = pipeline.transform(new_movies)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
